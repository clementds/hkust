{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Description**\n",
        "---"
      ],
      "metadata": {
        "id": "J6wJqlmRp6Tz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. (60%) Suppose you have 1 M USD and want to invest in US stock market for 10 years (2012-2022). You will decide the portfolio every three months and buy and hold for three months.  At the beginning of every three months: using past 6 months data to compute the risk and correlation of composite stocks of **Nasdaq 100**.\n",
        "  - Select the first stock which has the smallest average of absolute values of correlations with other stocks\n",
        "  - Select the second stock which has the smallest absolute values of correlation with the first selected one\n",
        "  - Select the third stock which has the smallest average of absolute values of correlations with the first two selected stocks.\n",
        "  - Repeat until you have 10 stocks.\n",
        "  \n",
        "  In this assignment, we will take **global minimum variance portfolio (using multiple regression)**\n",
        "\n",
        "2. (40%)  Compute the maximum drawdown, annual sharpe ratio of your invesment in these 10 years. Try this strategy for the year of 2023 and get the maximum drawdown and annual sharpe ratio. Compare the measures to evaluate whether the performance is consistent.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ruqp21BEp_vS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SETIABUDHI, Clement Darmawan (SID: 20817485)"
      ],
      "metadata": {
        "id": "n9STka9ygnIg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoBckZy-p2JP"
      },
      "outputs": [],
      "source": [
        "!pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yahoo_fin"
      ],
      "metadata": {
        "id": "2tX0ccCrq5cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1:"
      ],
      "metadata": {
        "id": "97gDHyl_qGas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary libraries/tools\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from typing import List\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import statsmodels.api as sm\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "gUMFXwZ2qCV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Downloading necessary data\n",
        "def download_data(ticker: str, start: str, end: str) -> pd.DataFrame:\n",
        "    return yf.download(ticker, start=start, end=end)\n",
        "    if data is None:\n",
        "        print(f\"No data available for {ticker} between {start} and {end}\")\n",
        "    return data"
      ],
      "metadata": {
        "id": "_J79HmdKqJHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Formula to calculate correlation\n",
        "def calculate_correlation_matrix(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    return df.pct_change().corr()"
      ],
      "metadata": {
        "id": "fK_9itdEqLl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Formula to calculate variance\n",
        "def calculate_variance(df: pd.DataFrame) -> pd.Series:\n",
        "    return df.pct_change().var()"
      ],
      "metadata": {
        "id": "tCkC09v1qM88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Selecting the smallest average of absolute values of correlations\n",
        "def select_stocks(correlation_matrix: pd.DataFrame, num_stocks: int) -> List[str]:\n",
        "    selected_stocks = []\n",
        "    remaining_stocks = list(correlation_matrix.columns)\n",
        "\n",
        "    for i in range(num_stocks):\n",
        "        min_corr_stock = None\n",
        "        min_corr = float('inf')\n",
        "\n",
        "        for stock in remaining_stocks:\n",
        "            if i == 0:  # First stock selection\n",
        "                avg_corr = correlation_matrix[stock].abs().mean() #make it absolute\n",
        "            elif i == 1:  # Second stock selection\n",
        "                avg_corr = abs(correlation_matrix.loc[selected_stocks[0], stock])\n",
        "            else:\n",
        "                avg_corr = correlation_matrix.loc[selected_stocks, stock].abs().mean()\n",
        "\n",
        "            if avg_corr < min_corr:\n",
        "                min_corr = avg_corr\n",
        "                min_corr_stock = stock\n",
        "\n",
        "        selected_stocks.append(min_corr_stock)\n",
        "        remaining_stocks.remove(min_corr_stock)\n",
        "\n",
        "    return selected_stocks"
      ],
      "metadata": {
        "id": "xxBhrOu7qP0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating weights and taking global minimum variance portfolio (using multiple regression)\n",
        "def calculate_weights(variance: pd.Series, selected_stocks: List[str], market_returns: pd.Series, variances: pd.Series, prices_df: pd.DataFrame) -> pd.Series:\n",
        "    market_returns = prices_df.mean(axis=1).pct_change().dropna()\n",
        "    prices_df['market_returns'] = market_returns\n",
        "    prices_df['market_returns'].fillna(prices_df['market_returns'].mean(), inplace=True)\n",
        "    prices_df['market_returns'].replace([np.inf, -np.inf], 1e6, inplace=True)\n",
        "\n",
        "    variances = prices_df.var(axis=0, ddof=1)\n",
        "    prices_df['variances'] = variances\n",
        "    prices_df['variances'].fillna(1e6, inplace=True)\n",
        "    prices_df['variances'].replace([np.inf, -np.inf], 1e6, inplace=True)\n",
        "\n",
        "    selected_stocks = list(set(selected_stocks).intersection(prices_df.index))\n",
        "    missing_stocks = set(selected_stocks) - set(prices_df.index)\n",
        "    if missing_stocks:\n",
        "        raise ValueError(f\"The following stocks are missing from the prices_df DataFrame: {missing_stocks}\")\n",
        "\n",
        "    returns_df = prices_df.loc[selected_stocks].pct_change().dropna()\n",
        "    selected_variances = variance.loc[selected_stocks]\n",
        "    selected_variances = selected_variances.fillna(selected_variances.mean())\n",
        "    selected_variances.replace([np.inf, -np.inf], 1e6, inplace=True)\n",
        "\n",
        "#Multiple regression\n",
        "    X = sm.add_constant(prices_df[['market_returns', 'variances']])\n",
        "    y = pd.Series(0, index=prices_df.index)\n",
        "    y.loc[selected_stocks] = 1\n",
        "    model = sm.OLS(y, X, missing='drop')\n",
        "    results = model.fit()\n",
        "    weight = results.params[1:]\n",
        "    weight /= weight.sum()\n",
        "    return weight"
      ],
      "metadata": {
        "id": "eNHwGZUEK7TG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparation\n",
        "risk_free_rate = 0.02\n",
        "start_date = '2012-01-01'\n",
        "end_date = '2022-12-31'\n",
        "initial = 1000000 #total amount\n",
        "variance = pd.Series\n",
        "selected_stocks = List[str]\n",
        "market_returns = pd.Series\n",
        "variances = pd.Series\n",
        "\n",
        "#Importing Nasdaq 100 tickers\n",
        "nasdaq100list = pd.read_html(\"https://en.wikipedia.org/wiki/Nasdaq-100\")\n",
        "tickers = nasdaq100list[4][\"Ticker\"].tolist()\n",
        "\n",
        "num_stocks = 10\n",
        "quarters = pd.date_range(start=start_date, end=end_date, freq='Q', closed='right')\n",
        "portfolio_value = initial\n",
        "max_drawdown = 0\n",
        "all_returns= []\n",
        "wealth_process = pd.DataFrame({'date': [start_date], 'wealth': [initial]})\n",
        "wealth_process = wealth_process.set_index('date')\n",
        "all_wealth_processes = [] # Define an empty list to store wealth processes\n",
        "\n",
        "\n",
        "# Download Nasdaq 100 data\n",
        "ticker = \"^NDX\"\n",
        "nasdaq100_data = download_data(ticker, start_date, end_date)\n",
        "nasdaq100_prices = nasdaq100_data['Adj Close']\n",
        "nasdaq100_returns = nasdaq100_prices.pct_change().dropna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6BWRajDqhkV",
        "outputId": "bbea5991-870d-462e-fb29-2086290b85a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-104-57d5c479d05d>:16: FutureWarning: Argument `closed` is deprecated in favor of `inclusive`.\n",
            "  quarters = pd.date_range(start=start_date, end=end_date, freq='Q', closed='right')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Processing the data using all of the functions\n",
        "wealth_process = pd.DataFrame({'date': [start_date], 'wealth': [initial]})\n",
        "wealth_process = wealth_process.set_index('date')\n",
        "\n",
        "for quarter_end in quarters:\n",
        "    start = (quarter_end - pd.DateOffset(months=6)).strftime('%Y-%m-%d')\n",
        "    end = quarter_end.strftime('%Y-%m-%d')\n",
        "\n",
        "    data = {}\n",
        "    for ticker in tickers:\n",
        "      try:\n",
        "        data[ticker] = download_data(ticker, start, end)\n",
        "      except BaseException:\n",
        "        print(f\"Error downloading data for {ticker}\")\n",
        "        data[ticker] = None\n",
        "\n",
        "    prices_df = pd.DataFrame({ticker: df['Adj Close'] for ticker, df in data.items() if df is not None})\n",
        "\n",
        "    correlation_matrix = calculate_correlation_matrix(prices_df)\n",
        "    variance = calculate_variance(prices_df)\n",
        "\n",
        "    selected_stocks = select_stocks(correlation_matrix, num_stocks)\n",
        "\n",
        "    market_returns = prices_df.mean(axis=1).pct_change().dropna()\n",
        "    prices_df['market_returns'] = market_returns\n",
        "    prices_df['market_returns'].fillna(prices_df['market_returns'].mean(), inplace=True)\n",
        "    prices_df['market_returns'].replace([np.inf, -np.inf], 1e6, inplace=True)\n",
        "\n",
        "    variances = prices_df.var(axis=0, ddof=1)\n",
        "    prices_df['variances'] = variances\n",
        "    prices_df['variances'].fillna(1e6, inplace=True)\n",
        "    selected_variances = variance.loc[selected_stocks]\n",
        "    selected_variances = selected_variances.fillna(selected_variances.mean())\n",
        "    selected_variances.replace([np.inf, -np.inf], 1e6, inplace=True)\n",
        "\n",
        "    weights = calculate_weights(variances, selected_stocks, prices_df['market_returns'], prices_df['variances'], prices_df)\n",
        "\n",
        "    start_next_quarter = (quarter_end + pd.DateOffset(days=1)).strftime('%Y-%m-%d')\n",
        "    end_next_quarter = (quarter_end + pd.DateOffset(months=3)).strftime('%Y-%m-%d')\n",
        "\n",
        "    next_quarter_data = {ticker: download_data(ticker, start_next_quarter, end_next_quarter) for ticker in selected_stocks}\n",
        "    next_quarter_prices_df = pd.DataFrame({ticker: df['Adj Close'] for ticker, df in next_quarter_data.items()})\n",
        "    returns = next_quarter_prices_df.pct_change().dropna()\n",
        "\n",
        "    # Compute daily returns\n",
        "    daily_returns = (weights * returns).sum(axis=1)\n",
        "    all_returns.extend(daily_returns)\n",
        "\n",
        "    # Update wealth process\n",
        "    end_date = pd.to_datetime(end_next_quarter).date()\n",
        "    start_date = end_date - pd.DateOffset(months=3) + pd.DateOffset(days=1)\n",
        "\n",
        "    wealth_period = nasdaq100_returns.loc[start_date:end_date] + 1\n",
        "    wealth_process_quarter = wealth_period.cumprod() * portfolio_value\n",
        "    wealth_process_quarter = pd.DataFrame({'date': wealth_process_quarter.index, 'wealth': wealth_process_quarter.values})\n",
        "    wealth_process_quarter = wealth_process_quarter.set_index('date')\n",
        "    wealth_process = wealth_process.append(wealth_process_quarter)\n",
        "\n",
        "    portfolio_value = wealth_process.iloc[-1]['wealth']"
      ],
      "metadata": {
        "id": "9QPH7ig3Tefw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2:"
      ],
      "metadata": {
        "id": "f3wz9qAFqlW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to calculate maximum drawdown\n",
        "def calculate_max_drawdown(wealth_process: pd.DataFrame) -> float:\n",
        "    max_drawdown = 0\n",
        "    peak = wealth_process.iloc[0]['wealth']\n",
        "    for _, row in wealth_process.iterrows():\n",
        "        if row['wealth'] > peak:\n",
        "            peak = row['wealth']\n",
        "        drawdown = (peak - row['wealth']) / peak\n",
        "        if drawdown > max_drawdown:\n",
        "            max_drawdown = drawdown\n",
        "    return max_drawdown\n",
        "    if len(wealth_process) == 0:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "X-EDMWCjql10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to calculate annual sharpe ratio\n",
        "def calculate_sharpe_ratio(returns: np.ndarray, risk_free_rate: float) -> float:\n",
        "    excess_returns = returns - risk_free_rate\n",
        "    average_excess_return = np.mean(excess_returns)\n",
        "    std_deviation = np.std(returns)\n",
        "    sharpe_ratio = average_excess_return / std_deviation\n",
        "    return sharpe_ratio"
      ],
      "metadata": {
        "id": "5XJd78puaLtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_nasdaq100_tickers():\n",
        "    nasdaq100 = yf.Ticker(\"^NDX\")\n",
        "    nasdaq100_constituents = nasdaq100.sustainability['constituents'].split(' ')\n",
        "    return nasdaq100_constituents[:-1] # Remove the last empty element"
      ],
      "metadata": {
        "id": "unBGtp_Rq2IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating maximum drawdown, annual sharpe ratio of invesment during 2012-2022\n",
        "portfolio_returns = wealth_process['wealth'].pct_change().fillna(0)\n",
        "max_drawdown = calculate_max_drawdown(wealth_process)\n",
        "sharpe_ratio = calculate_sharpe_ratio(returns, risk_free_rate)\n",
        "\n",
        "print(f\"Portfolio Value after 10 years: ${wealth_process.iloc[-1]['wealth']:.2f}\")\n",
        "print(f\"Maximum Drawdown for 2012-2022: {max_drawdown * 100:.2f}%\")\n",
        "print(f\"Annual Sharpe Ratio for 2012-2022: \", sharpe_ratio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtlPJ6FRq30M",
        "outputId": "a9206f8e-a507-469c-96e8-bd32701d3f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Portfolio Value after 10 years: $3865793.76\n",
            "Maximum Drawdown for 2012-2022: 36.28%\n",
            "Annual Sharpe Ratio for 2012-2022:  KHC    -1.615193\n",
            "WBD    -0.358638\n",
            "ENPH   -0.678933\n",
            "REGN   -0.940855\n",
            "PDD    -0.521618\n",
            "SGEN   -0.374335\n",
            "FANG   -0.819191\n",
            "ATVI   -1.099388\n",
            "DLTR   -1.214224\n",
            "CEG    -1.105293\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3472: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating maximum drawdown, annual sharpe ratio of invesment during 2023\n",
        "\n",
        "#Preparation\n",
        "risk_free_rate = 0.02\n",
        "start_date = '2023-01-01'\n",
        "end_date = datetime.today().strftime('%Y-%m-%d')\n",
        "initial = 1000000 #total amount\n",
        "variance = pd.Series\n",
        "selected_stocks = List[str]\n",
        "market_returns = pd.Series\n",
        "variances = pd.Series\n",
        "\n",
        "#Importing Nasdaq 100 tickers\n",
        "nasdaq100list = pd.read_html(\"https://en.wikipedia.org/wiki/Nasdaq-100\")\n",
        "tickers = nasdaq100list[4][\"Ticker\"].tolist()\n",
        "\n",
        "num_stocks = 10\n",
        "quarters = pd.date_range(start=start_date, end=end_date, freq='Q', closed='right')\n",
        "portfolio_value = initial\n",
        "max_drawdown = 0\n",
        "all_returns= []\n",
        "wealth_process = pd.DataFrame({'date': [start_date], 'wealth': [initial]})\n",
        "wealth_process = wealth_process.set_index('date')\n",
        "all_wealth_processes = [] # Define an empty list to store wealth processes\n",
        "\n",
        "\n",
        "# Download Nasdaq 100 data\n",
        "ticker = \"^NDX\"\n",
        "nasdaq100_data = download_data(ticker, start_date, end_date)\n",
        "nasdaq100_prices = nasdaq100_data['Adj Close']\n",
        "nasdaq100_returns = nasdaq100_prices.pct_change().dropna()\n",
        "\n",
        "#Processing the data using all of the functions\n",
        "wealth_process = pd.DataFrame({'date': [start_date], 'wealth': [initial]})\n",
        "wealth_process = wealth_process.set_index('date')\n",
        "\n",
        "for quarter_end in quarters:\n",
        "    start = (quarter_end - pd.DateOffset(months=6)).strftime('%Y-%m-%d')\n",
        "    end = quarter_end.strftime('%Y-%m-%d')\n",
        "\n",
        "    data = {}\n",
        "    for ticker in tickers:\n",
        "      try:\n",
        "        data[ticker] = download_data(ticker, start, end)\n",
        "      except BaseException:\n",
        "        print(f\"Error downloading data for {ticker}\")\n",
        "        data[ticker] = None\n",
        "\n",
        "    prices_df = pd.DataFrame({ticker: df['Adj Close'] for ticker, df in data.items() if df is not None})\n",
        "\n",
        "    correlation_matrix = calculate_correlation_matrix(prices_df)\n",
        "    variance = calculate_variance(prices_df)\n",
        "\n",
        "    selected_stocks = select_stocks(correlation_matrix, num_stocks)\n",
        "\n",
        "    market_returns = prices_df.mean(axis=1).pct_change().dropna()\n",
        "    prices_df['market_returns'] = market_returns\n",
        "    prices_df['market_returns'].fillna(prices_df['market_returns'].mean(), inplace=True)\n",
        "    prices_df['market_returns'].replace([np.inf, -np.inf], 1e6, inplace=True)\n",
        "\n",
        "    variances = prices_df.var(axis=0, ddof=1)\n",
        "    prices_df['variances'] = variances\n",
        "    prices_df['variances'].fillna(1e6, inplace=True)\n",
        "    selected_variances = variance.loc[selected_stocks]\n",
        "    selected_variances = selected_variances.fillna(selected_variances.mean())\n",
        "    selected_variances.replace([np.inf, -np.inf], 1e6, inplace=True)\n",
        "\n",
        "    weights = calculate_weights(variances, selected_stocks, prices_df['market_returns'], prices_df['variances'], prices_df)\n",
        "\n",
        "    start_next_quarter = (quarter_end + pd.DateOffset(days=1)).strftime('%Y-%m-%d')\n",
        "    end_next_quarter = (quarter_end + pd.DateOffset(months=3)).strftime('%Y-%m-%d')\n",
        "\n",
        "    next_quarter_data = {ticker: download_data(ticker, start_next_quarter, end_next_quarter) for ticker in selected_stocks}\n",
        "    next_quarter_prices_df = pd.DataFrame({ticker: df['Adj Close'] for ticker, df in next_quarter_data.items()})\n",
        "    returns = next_quarter_prices_df.pct_change().dropna()\n",
        "\n",
        "    # Compute daily returns\n",
        "    daily_returns = (weights * returns).sum(axis=1)\n",
        "    all_returns.extend(daily_returns)\n",
        "\n",
        "    # Update wealth process\n",
        "    end_date = pd.to_datetime(end_next_quarter).date()\n",
        "    start_date = end_date - pd.DateOffset(months=3) + pd.DateOffset(days=1)\n",
        "\n",
        "    wealth_period = nasdaq100_returns.loc[start_date:end_date] + 1\n",
        "    wealth_process_quarter = wealth_period.cumprod() * portfolio_value\n",
        "    wealth_process_quarter = pd.DataFrame({'date': wealth_process_quarter.index, 'wealth': wealth_process_quarter.values})\n",
        "    wealth_process_quarter = wealth_process_quarter.set_index('date')\n",
        "    wealth_process = wealth_process.append(wealth_process_quarter)\n",
        "\n",
        "    portfolio_value = wealth_process.iloc[-1]['wealth']\n",
        "\n",
        "portfolio_returns = wealth_process['wealth'].pct_change().fillna(0)\n",
        "max_drawdown = calculate_max_drawdown(wealth_process)\n",
        "sharpe_ratio = calculate_sharpe_ratio(returns, risk_free_rate)\n",
        "\n",
        "print(f\"Portfolio Value for 2023: ${wealth_process.iloc[-1]['wealth']:.2f}\")\n",
        "print(f\"Maximum Drawdown for 2023: {max_drawdown * 100:.2f}%\")\n",
        "print(f\"Annual Sharpe Ratio for 2023: \", sharpe_ratio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2Ra_GiHaZCm",
        "outputId": "ac157ba9-c5cf-44a7-f481-fa794b246a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-114-e8a5a4ad270c>:18: FutureWarning: Argument `closed` is deprecated in favor of `inclusive`.\n",
            "  quarters = pd.date_range(start=start_date, end=end_date, freq='Q', closed='right')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Portfolio Value for 2023: $1032911.83\n",
            "Maximum Drawdown for 2023: 3.46%\n",
            "Annual Sharpe Ratio for 2023:  SGEN   -4.120777\n",
            "CEG    -1.868711\n",
            "META   -0.569487\n",
            "AMGN   -1.979602\n",
            "PDD    -0.991031\n",
            "FANG   -1.130738\n",
            "ATVI   -1.021452\n",
            "GILD   -2.013554\n",
            "PANW   -1.081257\n",
            "LCID   -0.521279\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-114-e8a5a4ad270c>:89: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  wealth_process = wealth_process.append(wealth_process_quarter)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3472: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        }
      ]
    }
  ]
}